# Design Document

## 取り組んだ課題
- 宿題1と宿題2
- 宿題1: wiki.py, bfs.py
- 宿題2: wiki.py, pagerank.py
  - ページランクが高いもの上位10個を表示している    
  - 全ノード数が10に満たないものについては、ページランクが高い順に全てのノードを表示


## 宿題1
- 課題内容: あるページから別のページへの最短経路を計算する

### 実装の方針
- 始点ノードから終点ノードまでの最短経路長を求めれば良い
- BFSによる経路探索を利用する
  - BFSでは、既に訪れた頂点を記憶しておく必要がある
  - 頂点を記憶する際に、始点ノードからの距離も記憶しておくようにする
    - (始点ノードから子ノードの距離) = (始点ノードから親ノードの距離) + 1

### 実行結果
- データセット: large
- start: "渋谷", goal: "小野妹子"
- 経路長: 2
  - 実際、「渋谷」→「ギャルサー_テレビドラマ」→「小野妹子」という経路になる

### 工夫した点
- キューの実装: collections.deque()を持ちいた
  - キューへの要素の追加: append()
  - キューから要素を削除: popleft()
- enqueue, dequeueという関数を作成し、直感的に作業内容がわかるようにした  

## 宿題2
- 課題内容: ページランクを計算し、重要度の高いページトップ10を求める

### 実装の方針
- step1: 全部のノードに初期値1.0を与える: initialize_all_node()
- step2: 各ノードのページランクを振り分ける: calculate_pagerank() 
  - 子ノードがある場合: ページランクの85%を子ノードに均等に振り分ける
    - 残りの15%は全ノードに均等に振り分ける
  - 子ノードがない場合: ページランクを全ノードに均等に振り分ける
- step3: 各ノードのページランクを、受け取ったページランクの合計値に更新する: update_pagerank()
- step4: ページランクが収束するまで、step2とstep3を繰り返す: is_convergence()
  - 収束したかどうかは、全ノードについて以下のことが成り立っているかで判定
    - 更新前のページランクと更新後のページランクの差が0.1以下    

### 注意した点
- 各ノードのページランクを振り分ける際に、割り切れない場合がある
  - 1 / 3 = 0.333333...
  - そのため、全ノードのページランクの合計値は一定に保たれていることを確認したが、誤差があることに留意する必要があると考えた
    - largeでテストを行った際、0.1未満の誤差があることを確認した

### 実行結果
- データセット: medium
  - 英語
    ISBN
    2006年
    2005年
    2007年
    東京都 
    昭和
    2004年
    2003年
    2000年

- データセット: large
  - 英語
  ISBN
  2006年
  2005年
  2007年 
  東京都
  昭和
  2004年
  2003年
  2000年
  
### 考察
#### 実行時間について
- medium, largeについては、実行時間が長い
- Googleでもページランクの再計算(Google Dance)の頻度は1ヶ月に1回程度らしい
  - 参考資料: http://www.kentmiyajima.com/document/pagerank.pdf 
- 収束するまで全てのノードについてページランクを計算する必要があるので、計算量をO(N)から減らすことはできない
- 再計算の回数を減らすことができれば、実行時間を早めることができる
- 収束を早めることができれば良いと考えた

#### 収束条件について
- コンピュータで扱える桁数に限りがある以上、「収束した」=「全ノードのページランクが変化しなくなった」とするのは現実的でない
- そもそも重要度の高いページを求めることが目的なのだから、正確なページランクを求める必要はない
